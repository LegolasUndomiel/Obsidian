## 并行计算
**核心思想**
- 如何将并发计算映射到计算资源上

**两个领域**
- 计算机架构-硬件方面
- 并行程序设计-软件方面

**Harvard architecture**
#计算机原理 
- 内存(数据和指令)
- 中央处理单元(控制单元和算术逻辑单元)
- 输入/输出接口
### 串行编程和并行编程
#### 串行程序
把问题划分为许多小的运算块，每个运算块执行一个指定的任务，依次执行

有的运算块有**执行次序**，必须串行

#### 并行程序
没有执行次序的运算块，可以并发执行

**数据相关性**
一个任务的执行依赖另一个任务的输出，则二者相关，否则是独立的，相关性是限制并行的主要因素，梳理数据相关性有利于并行程序设计

### 并行性
两种并行类型：
- **任务并行**：任务可以独立、大规模并行执行，重点在于利用多核系统对任务进行分配
- **数据并行**：同时处理很多数据，重点利用在于多核系统对数据进行分配，CUDA适合解决数据并行计算问题

 数据划分方式：
 - 块划分(block partitioning)，线程处理整个数据块的一部分
 - 周期划分(cyclic partitioning)，线程需要处理数据的多个数据块
### 计算机架构
#计算机原理
**Flynn's Taxonomy**
- 单指令单数据(SISD)：传统计算机，一个核心，只有一个指令流处理一个数据流
- 单指令多数据(SIMD)：并行架构类型，多个核心，一个指令流同时处理不同的数据流，如向量机、block，**warp**等，**最大的优势**是，编程时可以按照串行逻辑思考，但实际是对并行数据操作，从而实现并行加速(block调用多个thread)，细节由**编译器**实现
- 多指令单数据(MISM)：多个指令流处理一个数据流
- 多指令多数据(MIMD)：**多个核心** 使用 **多个指令流** ***异步*** 处理 **多个数据流**，**MIMD架构一般会包含SIMD组件**(CUDA是典型的MIMD架构，block(warp)是SIMD)

计算机架构相关术语：
- 延迟：一个操作从开始到完成所需时间，微秒
- 带宽：单位时间可处理的数据量，GB/s
- 吞吐量：单位时间成功处理的运算数量，gflops

按 **内存组织方式** 分类：
- 分布式内存多节点系统：网络连接多个处理器，每个处理器有本地内存，处理器之间通过网络通信，例如服务器**集群**
- 共享内存多处理器系统：双处理器到几百个处理器，关联同一个物理内存，或者共享低延迟链路(PCI-Express或PCIe)

GPU代表了一种多核架构：SIMT(单指令多线程)
- 多线程
- MIMD
- SIMD
- 指令级并行

比较CPU与GPU
- CPU核心处理复杂控制逻辑
- GPU核心处理简单控制逻辑的数据并行任务，注重吞吐量

## 异构计算
### 异构架构
