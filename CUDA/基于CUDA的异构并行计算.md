> CUDA C编程权威指南
## 1 并行计算
**核心思想**
- 如何将并发计算映射到计算资源上

**两个领域**
- 计算机架构-硬件方面
- 并行程序设计-软件方面

**Harvard architecture**
#计算机原理 
- 内存(数据和指令)
- 中央处理单元(控制单元和算术逻辑单元)
- 输入/输出接口
### 1.1 串行编程和并行编程
#### 1.1.1 串行程序
把问题划分为许多小的运算块，每个运算块执行一个指定的任务，依次执行

有的运算块有**执行次序**，必须串行

#### 1.1.2 并行程序
没有执行次序的运算块，可以并发执行

**数据相关性**
一个任务的执行依赖另一个任务的输出，则二者相关，否则是独立的，相关性是限制并行的主要因素，梳理数据相关性有利于并行程序设计

### 1.2 并行性
#### 1.2.1 并行类型
- **任务并行**：任务可以独立、大规模并行执行，重点在于利用多核系统对任务进行分配
- **数据并行**：同时处理很多数据，重点利用在于多核系统对数据进行分配，CUDA适合解决数据并行计算问题

#### 1.2.2 数据划分方式
 - 块划分(block partitioning)，线程处理整个数据块的一部分
 - 周期划分(cyclic partitioning)，线程需要处理数据的多个数据块
### 1.3 计算机架构
#计算机原理
#### 1.3.1 Flynn's Taxonomy
- 单指令单数据(SISD)：传统计算机，一个核心，只有一个指令流处理一个数据流
- 单指令多数据(SIMD)：并行架构类型，多个核心，一个指令流同时处理不同的数据流，如向量机、block，**warp**等，**最大的优势**是，编程时可以按照串行逻辑思考，但实际是对并行数据操作，从而实现并行加速(block调用多个thread)，细节由**编译器**实现
- 多指令单数据(MISM)：多个指令流处理一个数据流
- 多指令多数据(MIMD)：**多个核心** 使用 **多个指令流** ***异步*** 处理 **多个数据流**，**MIMD架构一般会包含SIMD组件**(CUDA是典型的MIMD架构，block(warp)是SIMD)

计算机架构相关术语：
- 延迟：一个操作从开始到完成所需时间，微秒
- 带宽：单位时间可处理的数据量，GB/s
- 吞吐量：单位时间成功处理的运算数量，gflops

#### 1.3.2 内存组织方式
- 分布式内存多节点系统：网络连接多个处理器，每个处理器有本地内存，处理器之间通过网络通信，例如服务器**集群**
- 共享内存多处理器系统：双处理器到几百个处理器，关联同一个物理内存，或者共享低延迟链路(PCI-Express或PCIe)

GPU代表了一种多核架构：SIMT(单指令多线程)
- 多线程
- MIMD
- SIMD
- 指令级并行

比较CPU与GPU
- CPU核心处理复杂控制逻辑
- GPU核心处理简单控制逻辑的数据并行任务，注重吞吐量

## 2 异构计算
### 2.1 异构架构
#### 2.1.1 异构计算节点
- 主机端：CPU，负责管理设备端的环境、代码和数据，执行应用的初始化
- 设备端：GPU，GPU不是独立运行，而是CPU的协处理器，二者通过PCIe总线相连

**注**：
当使用和CPU物理上分离的硬件组件来提高应用中计算密集部分的执行速度时，这个组件称为一个 **硬件加速器**

两部分代码：
- 主机代码：运行在CPU上
- 设备代码：运行在GPU上，提高并行数据的处理执行速度

#### 2.1.2 GPU容量重要特征
- CUDA核心数量
- 内存大小

两个指标：
- 峰值计算性能：评估计算能力，每秒能处理的浮点运算的数量(GFlops、TFlops)
- 内存带宽：从内存中读取或写入数据的速率(GB/s)

### 2.2 异构计算范例
#### 2.2.1 CPU和GPU对比
- CPU优势：适合处理 **控制密集型** 任务，具有处理复杂逻辑和指令集并行性的能力
- GPU优势：适合处理 **计算密集型** 任务，处理由计算任务主导，带有简单控制流的工作，具有大量可编程的核心，支持大规模多线程运算

#### 2.2.2 区分范围标准
- 并行级
- 数据规模

**总结**
较小的数据规模、复杂的控制逻辑、很少的并行性，适用于CPU处理
较大的数据规模、大量的数据并行性，适用于GPU处理
使用CPU执行串行部分或任务并行部分，在GPU上执行数据密集型并行任务

#### 2.2.3 CPU线程与GPU线程
- CPU线程：通常是重量级的实体，上下文([CSDN-context](https://blog.csdn.net/caizir913/article/details/108826764)[知乎-context](https://zhuanlan.zhihu.com/p/650629290)[context切换](https://zhuanlan.zhihu.com/p/52845869))切换缓慢且开销大
- GPU线程：高度轻量级，处理大量并发、轻量级的线程，最大限度提高吞吐量

### 2.3 CUDA：一种异构计算平台
#### 2.3.1 CUDA平台
- CUDA加速库
- 编译器指令
- 应用程序接口
- 行业标准程序语言扩展(C/C++、Fortran、Python等)

#### 2.3.2 CUDA API
- CUDA Driver API：低级别的API，提供很多对GPU设备的控制
- CUDA Runtime API：高级API，每个Runtime API函数都被分解成传递给Driver API的基本运算，GPU上 **内核如何使用内存** 以及 **如何组织线程** 对性能影响更显著

#### 2.3.3 编译
nvcc编译器在编译过程中，将设备代码从主机代码中分离，主机代码使用C/C++编译器编译；设备代码(核函数)带有CUDA关键字，使用nvcc编译。
nvcc编译器以[LLVM开源编译系统](https://zhuanlan.zhihu.com/p/140462815)为基础

## 3 示例
关键字：
- `__global__`：函数从CPU调用，在GPU上执行
- `<<<>>>`：从主机端到设备端的代码调用，括号内参数是执行配置
- `cudaDeviceReset()`：显式释放和清空设备中的资源

### 3.1 CUDA编程结构
1. 分配GPU内存
2. 从CPU内存拷贝数据到GPU内存
3. 调用CUDA核函数完成运算
4. 从GPU拷贝数据到CPU内存
5. 释放GPU内存空间

## 4 总结
### 4.1 CPU优化
- **数据局部性**：数据重用以降低内存访问的延迟，如cache优化技术
- **时间局部性**：在相对较短时间段内数据、资源的重用
- **空间局部性**：相对接近的存储空间内数据元素的重用

### 4.2 CUDA优化
- 内存层次结构：共享内存(高速缓存)，为主内存节省带宽提高运行速度
- 线程层次结构：
- 阻塞同步

### 4.3 CUDA开发环境
- NVIDIA Nsight集成开发环境
- CUDA-GDB命令行调试
- 性能分析工具
- GPU设备管理工具